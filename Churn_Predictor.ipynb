{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 72195,
          "databundleVersionId": 7898622,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30664,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Churn Predictor",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:05.116659Z",
          "iopub.execute_input": "2024-03-12T00:47:05.116938Z",
          "iopub.status.idle": "2024-03-12T00:47:05.427218Z",
          "shell.execute_reply.started": "2024-03-12T00:47:05.116916Z",
          "shell.execute_reply": "2024-03-12T00:47:05.426337Z"
        },
        "trusted": true,
        "id": "KbAtA4WccgnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notebook done by Abhishek, Nikhil, Vishal"
      ],
      "metadata": {
        "id": "EmtYapmfcgnJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Given data - Columns\n",
        "###### customer_id - a unique customer identification number\n",
        "###### age - the age of the user\n",
        "###### location - the US state of the user\n",
        "###### subscription_type - type of subsciption\n",
        "###### payment_plan - how often the user pays, monthly of annually\n",
        "###### num_subscription_pauses - number of times the user has paused their subscription (max 2)\n",
        "###### payment_method - form of user payment\n",
        "###### customer_service_inquiries - the frequency of customer service inquiries from the user\n",
        "###### signup_date - date the user signed up for the music subscription service\n",
        "###### weekly_hours - average number of weekly listening hours\n",
        "###### average_session_length - average length of each music listening session (in hours)\n",
        "###### song_skip_rate - percentage of songs the user does not finish\n",
        "###### weekly_songs_played - average number of songs the user plays in a week\n",
        "###### weekly_unique_songs - average number of unique songs the user plays in a week\n",
        "###### num_favorite_artists - number of artists the user set as favorite artists\n",
        "###### num_platform_friends - number of user connections in the app\n",
        "###### num_playlists_created - number of playlists the user created\n",
        "###### num_shared_playlists - number of playlists that are shared publicly\n",
        "###### notifications_clicked - number of in-app notifications clicked on\n",
        "###### churned - this is the target variable, 0 = customer is active, 1 = customer churned"
      ],
      "metadata": {
        "id": "rt3grRfqcgnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing csv files\n",
        "trainDF = pd.read_csv(\"/kaggle/input/music-subscriptions-churn-predictor/train.csv\")\n",
        "testDF = pd.read_csv(\"/kaggle/input/music-subscriptions-churn-predictor/test.csv\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:06.678132Z",
          "iopub.execute_input": "2024-03-12T00:47:06.678805Z",
          "iopub.status.idle": "2024-03-12T00:47:06.717758Z",
          "shell.execute_reply.started": "2024-03-12T00:47:06.678779Z",
          "shell.execute_reply": "2024-03-12T00:47:06.716912Z"
        },
        "trusted": true,
        "id": "tEZuyaLccgnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainDF.head() #viewing the data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:07.522989Z",
          "iopub.execute_input": "2024-03-12T00:47:07.52328Z",
          "iopub.status.idle": "2024-03-12T00:47:07.542275Z",
          "shell.execute_reply.started": "2024-03-12T00:47:07.523259Z",
          "shell.execute_reply": "2024-03-12T00:47:07.541689Z"
        },
        "trusted": true,
        "id": "lYsok4BkcgnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainDF.info()  #checking for nulls and checking the data types"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:08.005962Z",
          "iopub.execute_input": "2024-03-12T00:47:08.006251Z",
          "iopub.status.idle": "2024-03-12T00:47:08.020334Z",
          "shell.execute_reply.started": "2024-03-12T00:47:08.006231Z",
          "shell.execute_reply": "2024-03-12T00:47:08.01929Z"
        },
        "trusted": true,
        "id": "Q6x3lvT3cgnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "objects = ['location','subscription_type', 'payment_plan','payment_method','customer_service_inquiries'] #created a list of object types"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:08.527459Z",
          "iopub.execute_input": "2024-03-12T00:47:08.527772Z",
          "iopub.status.idle": "2024-03-12T00:47:08.53213Z",
          "shell.execute_reply.started": "2024-03-12T00:47:08.52775Z",
          "shell.execute_reply": "2024-03-12T00:47:08.530965Z"
        },
        "trusted": true,
        "id": "vC-5Sc7-cgnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in objects:\n",
        "    print(trainDF[i].unique()) #viewing the unique values in object columns"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:08.933153Z",
          "iopub.execute_input": "2024-03-12T00:47:08.933448Z",
          "iopub.status.idle": "2024-03-12T00:47:08.942651Z",
          "shell.execute_reply.started": "2024-03-12T00:47:08.933427Z",
          "shell.execute_reply": "2024-03-12T00:47:08.941746Z"
        },
        "trusted": true,
        "id": "kumFTrBVcgnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainDF.describe()   #checking for any discrapancies in the distribution"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:09.326489Z",
          "iopub.execute_input": "2024-03-12T00:47:09.326849Z",
          "iopub.status.idle": "2024-03-12T00:47:09.367257Z",
          "shell.execute_reply.started": "2024-03-12T00:47:09.326826Z",
          "shell.execute_reply": "2024-03-12T00:47:09.3663Z"
        },
        "trusted": true,
        "id": "ikal_UEycgnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Changing datetype to numerical columns"
      ],
      "metadata": {
        "id": "vZtIOZ29cgnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "year = []\n",
        "month = []\n",
        "day = []\n",
        "\n",
        "for i in list(trainDF['signup_date']):\n",
        "# Creating a Timestamp object\n",
        "    timestamp = pd.Timestamp(i)\n",
        "\n",
        "# Extracting the year from the Timestamp\n",
        "    year.append(timestamp.year)\n",
        "\n",
        "# Extracting the month from the Timestamp\n",
        "    month.append(timestamp.month)\n",
        "\n",
        "# Extracting the day from the Timestamp\n",
        "    day.append(timestamp.day)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:09.706418Z",
          "iopub.execute_input": "2024-03-12T00:47:09.706987Z",
          "iopub.status.idle": "2024-03-12T00:47:09.737839Z",
          "shell.execute_reply.started": "2024-03-12T00:47:09.706962Z",
          "shell.execute_reply": "2024-03-12T00:47:09.736633Z"
        },
        "trusted": true,
        "id": "7G2AdIrocgnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainDF['year'] = year\n",
        "trainDF['month'] = month\n",
        "trainDF['day'] = day"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:10.24961Z",
          "iopub.execute_input": "2024-03-12T00:47:10.249907Z",
          "iopub.status.idle": "2024-03-12T00:47:10.262821Z",
          "shell.execute_reply.started": "2024-03-12T00:47:10.249885Z",
          "shell.execute_reply": "2024-03-12T00:47:10.261699Z"
        },
        "trusted": true,
        "id": "KdSlfTgScgnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dropping unecessary columns"
      ],
      "metadata": {
        "id": "6JHbjjgycgnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainDF.drop('signup_date',axis =1,inplace = True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:10.853709Z",
          "iopub.execute_input": "2024-03-12T00:47:10.853986Z",
          "iopub.status.idle": "2024-03-12T00:47:10.858969Z",
          "shell.execute_reply.started": "2024-03-12T00:47:10.853965Z",
          "shell.execute_reply": "2024-03-12T00:47:10.858344Z"
        },
        "trusted": true,
        "id": "GPkO0kudcgnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainDF.drop('customer_id',axis =1,inplace = True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:11.29132Z",
          "iopub.execute_input": "2024-03-12T00:47:11.291647Z",
          "iopub.status.idle": "2024-03-12T00:47:11.298036Z",
          "shell.execute_reply.started": "2024-03-12T00:47:11.291624Z",
          "shell.execute_reply": "2024-03-12T00:47:11.296901Z"
        },
        "trusted": true,
        "id": "-zKsoccIcgnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using Label Encloder since it reduces the no. of columns used in the dataset"
      ],
      "metadata": {
        "id": "m7g5Fa-dcgnO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "for i in objects:\n",
        "    le = LabelEncoder()\n",
        "    le.fit(trainDF[i])\n",
        "    trainDF[i] = le.transform(trainDF[i])\n",
        "    testDF[i] = le.transform(testDF[i])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:11.753656Z",
          "iopub.execute_input": "2024-03-12T00:47:11.753972Z",
          "iopub.status.idle": "2024-03-12T00:47:12.095213Z",
          "shell.execute_reply.started": "2024-03-12T00:47:11.753948Z",
          "shell.execute_reply": "2024-03-12T00:47:12.09428Z"
        },
        "trusted": true,
        "id": "x2TZ20phcgnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainDF.info() #checking"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:12.136899Z",
          "iopub.execute_input": "2024-03-12T00:47:12.137514Z",
          "iopub.status.idle": "2024-03-12T00:47:12.148002Z",
          "shell.execute_reply.started": "2024-03-12T00:47:12.137491Z",
          "shell.execute_reply": "2024-03-12T00:47:12.147049Z"
        },
        "trusted": true,
        "id": "XBYes4bhcgnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Profiling"
      ],
      "metadata": {
        "id": "yFd7u7MIcgnO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a data profiling function\n",
        "def create_data_profiling_df(data: pd.DataFrame) -> pd.DataFrame:\n",
        "\n",
        "    # create an empty dataframe to gather information about each column\n",
        "    data_profiling_df = pd.DataFrame(columns = [\"column_name\",\n",
        "                                                \"column_type\",\n",
        "                                                \"unique_values\",\n",
        "                                                \"duplicate_values\",\n",
        "                                                \"null_values\",\n",
        "                                                \"max\",\n",
        "                                                \"min\",\n",
        "                                                \"range\",\n",
        "                                                \"IQR\"])\n",
        "\n",
        "    # loop through each column to add rows to the data_profiling_df dataframe\n",
        "    for column in data.columns:\n",
        "\n",
        "        # create an empty dictionary to store the columns data\n",
        "        column_dict = {}\n",
        "\n",
        "        try:\n",
        "            column_dict[\"column_name\"] = [column]\n",
        "            column_dict[\"column_type\"] = [data[column].dtypes]\n",
        "            column_dict[\"unique_values\"] = [len(data[column].unique())]\n",
        "            column_dict[\"duplicate_values\"] = [(data[column].shape[0] - data[column].isna().sum()) - len(data[column].unique())]\n",
        "            column_dict[\"null_values\"] = [data[column].isna().sum()]\n",
        "            column_dict[\"max\"] = [data[column].max() if (data[column].dtypes != object) else \"NA\"]\n",
        "            column_dict[\"min\"] = [data[column].min() if (data[column].dtypes != object) else \"NA\"]\n",
        "            column_dict[\"range\"] = [data[column].max() - data[column].min() if (data[column].dtypes != object) else \"NA\"]\n",
        "            column_dict[\"IQR\"] = [data[column].quantile(.75) - data[column].quantile(.25) if (data[column].dtypes != object) else \"NA\"]\n",
        "\n",
        "        except:\n",
        "            print(f\"unable to read column: {column}, you may want to drop this column\")\n",
        "\n",
        "        # add the information from the columns dict to the final dataframe\n",
        "        data_profiling_df = pd.concat([data_profiling_df, pd.DataFrame(column_dict)],\n",
        "                                      ignore_index = True)\n",
        "\n",
        "    # sort the final dataframe by unique values descending\n",
        "    data_profiling_df.sort_values(by = ['unique_values'],\n",
        "                                  ascending = [False],\n",
        "                                  inplace=True)\n",
        "\n",
        "    # print the function is complete\n",
        "    print(f\"data profiling complete, dataframe contains {len(data_profiling_df)} columns\")\n",
        "    return data_profiling_df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:12.402103Z",
          "iopub.execute_input": "2024-03-12T00:47:12.402415Z",
          "iopub.status.idle": "2024-03-12T00:47:12.412785Z",
          "shell.execute_reply.started": "2024-03-12T00:47:12.402392Z",
          "shell.execute_reply": "2024-03-12T00:47:12.411899Z"
        },
        "trusted": true,
        "id": "AlfMviiRcgnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run the data profiling function and print the dataframe\n",
        "data_profiling_df = create_data_profiling_df(data = trainDF)\n",
        "data_profiling_df\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:12.711189Z",
          "iopub.execute_input": "2024-03-12T00:47:12.711488Z",
          "iopub.status.idle": "2024-03-12T00:47:12.78626Z",
          "shell.execute_reply.started": "2024-03-12T00:47:12.711464Z",
          "shell.execute_reply": "2024-03-12T00:47:12.785515Z"
        },
        "trusted": true,
        "id": "LNafkB0scgnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking for outliers in the data"
      ],
      "metadata": {
        "id": "JcwwbtgDcgnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.boxplot(trainDF['notifications_clicked'])\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:13.242324Z",
          "iopub.execute_input": "2024-03-12T00:47:13.242641Z",
          "iopub.status.idle": "2024-03-12T00:47:13.3803Z",
          "shell.execute_reply.started": "2024-03-12T00:47:13.24262Z",
          "shell.execute_reply": "2024-03-12T00:47:13.379611Z"
        },
        "trusted": true,
        "id": "3ZCadwaIcgnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.boxplot(trainDF['weekly_unique_songs'])\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:13.484259Z",
          "iopub.execute_input": "2024-03-12T00:47:13.484979Z",
          "iopub.status.idle": "2024-03-12T00:47:13.602952Z",
          "shell.execute_reply.started": "2024-03-12T00:47:13.484953Z",
          "shell.execute_reply": "2024-03-12T00:47:13.602255Z"
        },
        "trusted": true,
        "id": "ezZhj26KcgnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.boxplot(trainDF['num_shared_playlists'])\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:13.745546Z",
          "iopub.execute_input": "2024-03-12T00:47:13.745884Z",
          "iopub.status.idle": "2024-03-12T00:47:13.924067Z",
          "shell.execute_reply.started": "2024-03-12T00:47:13.745862Z",
          "shell.execute_reply": "2024-03-12T00:47:13.923154Z"
        },
        "trusted": true,
        "id": "pKgIKw2GcgnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dropping any duplicate columns in training dataset\n",
        "trainDF.drop_duplicates(inplace = True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:14.122906Z",
          "iopub.execute_input": "2024-03-12T00:47:14.123204Z",
          "iopub.status.idle": "2024-03-12T00:47:14.136143Z",
          "shell.execute_reply.started": "2024-03-12T00:47:14.123184Z",
          "shell.execute_reply": "2024-03-12T00:47:14.135061Z"
        },
        "trusted": true,
        "id": "wcGer-wdcgnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating target variable and training set\n",
        "y = trainDF['churned']\n",
        "trainDF.drop('churned',axis = 1, inplace = True)\n",
        "X = trainDF"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:14.456147Z",
          "iopub.execute_input": "2024-03-12T00:47:14.456525Z",
          "iopub.status.idle": "2024-03-12T00:47:14.463043Z",
          "shell.execute_reply.started": "2024-03-12T00:47:14.456501Z",
          "shell.execute_reply": "2024-03-12T00:47:14.461871Z"
        },
        "trusted": true,
        "id": "gD8nyOdvcgnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:14.724234Z",
          "iopub.execute_input": "2024-03-12T00:47:14.724519Z",
          "iopub.status.idle": "2024-03-12T00:47:14.735164Z",
          "shell.execute_reply.started": "2024-03-12T00:47:14.724499Z",
          "shell.execute_reply": "2024-03-12T00:47:14.734125Z"
        },
        "trusted": true,
        "id": "YABPhR2scgnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:15.032177Z",
          "iopub.execute_input": "2024-03-12T00:47:15.032851Z",
          "iopub.status.idle": "2024-03-12T00:47:15.040958Z",
          "shell.execute_reply.started": "2024-03-12T00:47:15.032828Z",
          "shell.execute_reply": "2024-03-12T00:47:15.039948Z"
        },
        "trusted": true,
        "id": "u-GpMbW1cgnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Engineering"
      ],
      "metadata": {
        "id": "1CttstMCcgnQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's use a correlation coefficient to determine which features to filter out\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# create correlation matrix\n",
        "corr_matrix = X.corr().abs()\n",
        "\n",
        "# the upper triangle of correlation matrix\n",
        "upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "\n",
        "# plot the heatmap of the upper triangle\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(upper_triangle, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
        "plt.title('Correlation Heatmap of Features')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:15.708386Z",
          "iopub.execute_input": "2024-03-12T00:47:15.708742Z",
          "iopub.status.idle": "2024-03-12T00:47:16.487383Z",
          "shell.execute_reply.started": "2024-03-12T00:47:15.708712Z",
          "shell.execute_reply": "2024-03-12T00:47:16.486342Z"
        },
        "trusted": true,
        "id": "XCnYjKtZcgnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to drop highly correlated features\n",
        "def find_highly_correlated_features(X: pd.DataFrame,\n",
        "                                    threshold=0.8) -> pd.DataFrame:\n",
        "\n",
        "    # create a  correlation matrix\n",
        "    corr_matrix = X.corr().abs()\n",
        "\n",
        "    # select the upper triangle of correlation matrix\n",
        "    upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "\n",
        "    # find features with correlation greater than the threshold\n",
        "    features_to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > threshold)]\n",
        "\n",
        "    # print and return the features to drop\n",
        "    print(f\"features dropped: {features_to_drop}\")\n",
        "    return features_to_drop"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:16.489032Z",
          "iopub.execute_input": "2024-03-12T00:47:16.489316Z",
          "iopub.status.idle": "2024-03-12T00:47:16.496464Z",
          "shell.execute_reply.started": "2024-03-12T00:47:16.489294Z",
          "shell.execute_reply": "2024-03-12T00:47:16.494796Z"
        },
        "trusted": true,
        "id": "KurYLrPQcgnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_to_drop = find_highly_correlated_features(X = X, threshold = 0.7)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:16.497556Z",
          "iopub.execute_input": "2024-03-12T00:47:16.497882Z",
          "iopub.status.idle": "2024-03-12T00:47:16.519801Z",
          "shell.execute_reply.started": "2024-03-12T00:47:16.497858Z",
          "shell.execute_reply": "2024-03-12T00:47:16.518853Z"
        },
        "trusted": true,
        "id": "P547WNAbcgnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.drop(columns=features_to_drop,axis =1 , inplace = True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:16.648842Z",
          "iopub.execute_input": "2024-03-12T00:47:16.649136Z",
          "iopub.status.idle": "2024-03-12T00:47:16.65461Z",
          "shell.execute_reply.started": "2024-03-12T00:47:16.649116Z",
          "shell.execute_reply": "2024-03-12T00:47:16.653697Z"
        },
        "trusted": true,
        "id": "ga_kBvwFcgnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.info() #checking"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:17.224036Z",
          "iopub.execute_input": "2024-03-12T00:47:17.224341Z",
          "iopub.status.idle": "2024-03-12T00:47:17.234725Z",
          "shell.execute_reply.started": "2024-03-12T00:47:17.224317Z",
          "shell.execute_reply": "2024-03-12T00:47:17.233626Z"
        },
        "trusted": true,
        "id": "v19WtdKWcgnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:17.641019Z",
          "iopub.execute_input": "2024-03-12T00:47:17.641324Z",
          "iopub.status.idle": "2024-03-12T00:47:17.649317Z",
          "shell.execute_reply.started": "2024-03-12T00:47:17.641299Z",
          "shell.execute_reply": "2024-03-12T00:47:17.648297Z"
        },
        "trusted": true,
        "id": "tBXOf6HVcgnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preparation"
      ],
      "metadata": {
        "id": "RvOOf0LdcgnS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split X and y into training and testing sets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 100)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:34.898617Z",
          "iopub.execute_input": "2024-03-12T00:47:34.898932Z",
          "iopub.status.idle": "2024-03-12T00:47:34.906852Z",
          "shell.execute_reply.started": "2024-03-12T00:47:34.89891Z",
          "shell.execute_reply": "2024-03-12T00:47:34.905849Z"
        },
        "trusted": true,
        "id": "VYzhxfI9cgnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalization"
      ],
      "metadata": {
        "id": "MZrjrf7PcgnS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### using robust Scaler since it is better suited for the outliers found earlier"
      ],
      "metadata": {
        "id": "KzA3jZY3cgnT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "# fit and transform the scaler on the features\n",
        "scaler = RobustScaler()\n",
        "X_train = scaler.fit_transform(X_train)#_feature_selection)\n",
        "X_test = scaler.transform(X_test)#_feature_selection)\n",
        "\n",
        "# fit and transform the scaler on the features\n",
        "#scaler = MinMaxScaler()\n",
        "#X_train = scaler.fit_transform(X_train)#_feature_selection)\n",
        "#X_test = scaler.transform(X_test)#_feature_selection)\n",
        "\n",
        "# standardize the features\n",
        "#scaler = StandardScaler()\n",
        "#X_train = scaler.fit_transform(X_train)#_feature_selection)\n",
        "#X_test = scaler.transform(X_test)#_feature_selection)\n",
        "\n",
        "# apply PCA to reduce dimensionality\n",
        "#pca = PCA(n_components=2)\n",
        "#X_train = pca.fit_transform(X_train)\n",
        "#X_test = pca.transform(X_test)\n",
        "\n",
        "# apply LDA to reduce dimensionality\n",
        "#lda = LinearDiscriminantAnalysis(n_components=1)\n",
        "#X_train = lda.fit_transform(X_train, y_train)\n",
        "#X_test = lda.transform(X_test)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:36.109977Z",
          "iopub.execute_input": "2024-03-12T00:47:36.110312Z",
          "iopub.status.idle": "2024-03-12T00:47:36.128767Z",
          "shell.execute_reply.started": "2024-03-12T00:47:36.110287Z",
          "shell.execute_reply": "2024-03-12T00:47:36.127776Z"
        },
        "trusted": true,
        "id": "9EFkpLB6cgnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Classification Models"
      ],
      "metadata": {
        "id": "YGn2ZQu0cgnU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradient Boosting Classifier"
      ],
      "metadata": {
        "id": "kuxJzTIAcgnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import time\n",
        "\n",
        "# Create a Gradient Boosting Classifier\n",
        "start = time.time()\n",
        "clf = GradientBoostingClassifier(random_state=55)\n",
        "\n",
        "# Train the classifier on the training set\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model with a classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"No. of 1's predicted: \",np.count_nonzero(y_pred == 1))\n",
        "# print total time\n",
        "end = time.time()\n",
        "print(f\"completed in {round(end-start, 2)} seconds\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:37.665505Z",
          "iopub.execute_input": "2024-03-12T00:47:37.665819Z",
          "iopub.status.idle": "2024-03-12T00:47:39.266204Z",
          "shell.execute_reply.started": "2024-03-12T00:47:37.665797Z",
          "shell.execute_reply": "2024-03-12T00:47:39.265208Z"
        },
        "trusted": true,
        "id": "SHJeR7b0cgnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Tree"
      ],
      "metadata": {
        "id": "7JnSpOnVcgnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import time\n",
        "\n",
        "# Create a Decision Tree classifier\n",
        "start = time.time()\n",
        "clf = DecisionTreeClassifier(random_state=55)\n",
        "\n",
        "# Train the classifier on the training set\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model with a classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"No. of 1's predicted: \",np.count_nonzero(y_pred == 1))\n",
        "\n",
        "# print total time\n",
        "end = time.time()\n",
        "print(f\"completed in {round(end-start, 2)} seconds\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:39.269463Z",
          "iopub.execute_input": "2024-03-12T00:47:39.269815Z",
          "iopub.status.idle": "2024-03-12T00:47:39.393561Z",
          "shell.execute_reply.started": "2024-03-12T00:47:39.269788Z",
          "shell.execute_reply": "2024-03-12T00:47:39.3926Z"
        },
        "trusted": true,
        "id": "jfjK55p8cgnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM"
      ],
      "metadata": {
        "id": "BtzNrLn9cgnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "import time\n",
        "\n",
        "# Create a SVM classifier\n",
        "start = time.time()\n",
        "clf = SVC(random_state=55)\n",
        "\n",
        "# Train the classifier on the training set\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model with a classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"No. of 1's predicted: \",np.count_nonzero(y_pred == 1))\n",
        "# print total time\n",
        "end = time.time()\n",
        "print(f\"completed in {round(end-start, 2)} seconds\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:39.395304Z",
          "iopub.execute_input": "2024-03-12T00:47:39.395648Z",
          "iopub.status.idle": "2024-03-12T00:47:41.983599Z",
          "shell.execute_reply.started": "2024-03-12T00:47:39.39562Z",
          "shell.execute_reply": "2024-03-12T00:47:41.982527Z"
        },
        "trusted": true,
        "id": "ArXnKlYrcgnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forests Classifier"
      ],
      "metadata": {
        "id": "V3Udrf8hcgnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the model we are using\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import time\n",
        "# Instantiate model\n",
        "# Create a Decision Tree classifier\n",
        "start = time.time()\n",
        "clf =  RandomForestClassifier(n_estimators= 800, random_state=0)\n",
        "# Train the model on training data\n",
        "# Train the classifier on the training set\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model with a classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"No. of 1's predicted: \",np.count_nonzero(y_pred == 1))\n",
        "# print total time\n",
        "end = time.time()\n",
        "print(f\"completed in {round(end-start, 2)} seconds\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:41.985104Z",
          "iopub.execute_input": "2024-03-12T00:47:41.985328Z",
          "iopub.status.idle": "2024-03-12T00:47:53.903764Z",
          "shell.execute_reply.started": "2024-03-12T00:47:41.985309Z",
          "shell.execute_reply": "2024-03-12T00:47:53.903097Z"
        },
        "trusted": true,
        "id": "9q2bBkfPcgnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Gradient boosting classifier seems to do better with data imbalances"
      ],
      "metadata": {
        "id": "FfSCoUhhcgnW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing test data"
      ],
      "metadata": {
        "id": "zIejOrOacgnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testDF.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:53.904993Z",
          "iopub.execute_input": "2024-03-12T00:47:53.90541Z",
          "iopub.status.idle": "2024-03-12T00:47:53.916106Z",
          "shell.execute_reply.started": "2024-03-12T00:47:53.905387Z",
          "shell.execute_reply": "2024-03-12T00:47:53.915367Z"
        },
        "trusted": true,
        "id": "1oVLWI_7cgnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "year = []\n",
        "month = []\n",
        "day = []\n",
        "\n",
        "for i in list(testDF['signup_date']):\n",
        "# Creating a Timestamp object\n",
        "    timestamp = pd.Timestamp(i)\n",
        "\n",
        "# Extracting the year from the Timestamp\n",
        "    year.append(timestamp.year)\n",
        "\n",
        "# Extracting the month from the Timestamp\n",
        "    month.append(timestamp.month)\n",
        "\n",
        "# Extracting the day from the Timestamp\n",
        "    day.append(timestamp.day)\n",
        "\n",
        "testDF['year'] = year\n",
        "testDF['month'] = month\n",
        "testDF['day'] = day\n",
        "\n",
        "idSet = testDF['customer_id']\n",
        "testDF.drop('signup_date',axis =1,inplace = True)\n",
        "testDF.drop('customer_id',axis =1,inplace = True)\n",
        "testDF.drop(columns=features_to_drop,axis =1, inplace = True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:53.91708Z",
          "iopub.execute_input": "2024-03-12T00:47:53.91732Z",
          "iopub.status.idle": "2024-03-12T00:47:53.941003Z",
          "shell.execute_reply.started": "2024-03-12T00:47:53.917299Z",
          "shell.execute_reply": "2024-03-12T00:47:53.93996Z"
        },
        "trusted": true,
        "id": "iFrS7KFdcgnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idSet = pd.DataFrame(idSet, columns = ['customer_id'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:53.942729Z",
          "iopub.execute_input": "2024-03-12T00:47:53.94296Z",
          "iopub.status.idle": "2024-03-12T00:47:53.959109Z",
          "shell.execute_reply.started": "2024-03-12T00:47:53.94294Z",
          "shell.execute_reply": "2024-03-12T00:47:53.958378Z"
        },
        "trusted": true,
        "id": "hHiABIFtcgnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testDF.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:53.960288Z",
          "iopub.execute_input": "2024-03-12T00:47:53.960771Z",
          "iopub.status.idle": "2024-03-12T00:47:53.974505Z",
          "shell.execute_reply.started": "2024-03-12T00:47:53.960746Z",
          "shell.execute_reply": "2024-03-12T00:47:53.973506Z"
        },
        "trusted": true,
        "id": "AMJDPvuYcgnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testDF = scaler.transform(testDF)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:53.976064Z",
          "iopub.execute_input": "2024-03-12T00:47:53.976642Z",
          "iopub.status.idle": "2024-03-12T00:47:53.982444Z",
          "shell.execute_reply.started": "2024-03-12T00:47:53.976615Z",
          "shell.execute_reply": "2024-03-12T00:47:53.98162Z"
        },
        "trusted": true,
        "id": "-pDYsDUIcgnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making Predictions"
      ],
      "metadata": {
        "id": "IgTwjohhcgnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import time\n",
        "\n",
        "# Create a Gradient Boosting Classifier\n",
        "start = time.time()\n",
        "clf = GradientBoostingClassifier(random_state=55)\n",
        "\n",
        "# Train the classifier on the training set\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf.predict(testDF)\n",
        "\n",
        "# print total time\n",
        "end = time.time()\n",
        "print(\"No. of 1's predicted: \",np.count_nonzero(y_pred == 1))\n",
        "print(f\"completed in {round(end-start, 2)} seconds\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:53.983241Z",
          "iopub.execute_input": "2024-03-12T00:47:53.984013Z",
          "iopub.status.idle": "2024-03-12T00:47:55.469551Z",
          "shell.execute_reply.started": "2024-03-12T00:47:53.983992Z",
          "shell.execute_reply": "2024-03-12T00:47:55.468331Z"
        },
        "trusted": true,
        "id": "sggSAIdbcgnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pd.DataFrame(y_pred, columns = ['churned'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:55.470723Z",
          "iopub.execute_input": "2024-03-12T00:47:55.471018Z",
          "iopub.status.idle": "2024-03-12T00:47:55.475381Z",
          "shell.execute_reply.started": "2024-03-12T00:47:55.470995Z",
          "shell.execute_reply": "2024-03-12T00:47:55.474618Z"
        },
        "trusted": true,
        "id": "N0fU0iODcgnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = pd.concat([idSet, y_pred],axis =1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:55.476288Z",
          "iopub.execute_input": "2024-03-12T00:47:55.476504Z",
          "iopub.status.idle": "2024-03-12T00:47:55.487737Z",
          "shell.execute_reply.started": "2024-03-12T00:47:55.476485Z",
          "shell.execute_reply": "2024-03-12T00:47:55.487Z"
        },
        "trusted": true,
        "id": "OmjPSQeLcgnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:55.490309Z",
          "iopub.execute_input": "2024-03-12T00:47:55.491208Z",
          "iopub.status.idle": "2024-03-12T00:47:55.504416Z",
          "shell.execute_reply.started": "2024-03-12T00:47:55.49118Z",
          "shell.execute_reply": "2024-03-12T00:47:55.503613Z"
        },
        "trusted": true,
        "id": "UlJHjIWRcgnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output.to_csv(\"submission.csv\", index = False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-12T00:47:55.505361Z",
          "iopub.execute_input": "2024-03-12T00:47:55.505663Z",
          "iopub.status.idle": "2024-03-12T00:47:55.517661Z",
          "shell.execute_reply.started": "2024-03-12T00:47:55.505638Z",
          "shell.execute_reply": "2024-03-12T00:47:55.516846Z"
        },
        "trusted": true,
        "id": "omNR9P9ocgnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With your model, can we reliably predict which customers will churn?\n",
        "### With a good training accuracy of 90 percent and good precision and recall, we are pretty sure that it will churn the customers good, and not make lose to the company.\n",
        "\n",
        "## How does your model work?\n",
        "### Our model is based on Gradient boosting, since it is the best model from my test results in predicting imbalaances in the data. Other models falsely predict the churn or just give 0's as output.\n",
        "\n",
        "## From the 2,500 customers in the testing data (test.csv), what percentage of customers do you expect we will retain?\n",
        "### We expect we can retain about 90-92% of the customers, that is nearly 2300 customers. This metric is obtained from the accuracy and precision of 90% of the gradient boosting classifier model"
      ],
      "metadata": {
        "id": "Y-pe-v7LcgnY"
      }
    }
  ]
}